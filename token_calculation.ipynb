{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/afreens/ragged', '/home/afreens/KILT', '/home/afreens/miniconda3/envs/vlr/lib/python38.zip', '/home/afreens/miniconda3/envs/vlr/lib/python3.8', '/home/afreens/miniconda3/envs/vlr/lib/python3.8/lib-dynload', '', '/home/afreens/miniconda3/envs/vlr/lib/python3.8/site-packages', '../']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "print(sys.path)\n",
    "from file_utils import load_jsonl, save_jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colbert_dataset_map = {\n",
    "    \"nq\": \"/data/tir/projects/tir6/general/afreens/dbqa/retriever_results/predictions/colbert/nq-dev-kilt.jsonl\",\n",
    "    \"bioasq\": \"/data/tir/projects/tir6/general/afreens/dbqa/retriever_results/predictions/colbert/complete_bioasq.jsonl\",\n",
    "    \"hotpotqa\": \"/data/tir/projects/tir6/general/afreens/dbqa/retriever_results/predictions/colbert/hotpotqa-dev-kilt.jsonl\"\n",
    "}\n",
    "\n",
    "colbert_dataset_map = {\n",
    "    \"nq\": \"nq-dev-kilt.jsonl\",\n",
    "    \"bioasq\": \"complete_bioasq.jsonl\",\n",
    "    \"hotpotqa\": \"hotpotqa-dev-kilt.jsonl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "INSTRUCTION_STR = \"Give simple short one phrase answers for the questions based on the context\"\n",
    "NO_CONTEXT_INSTRUCTION_STR = \"Give simple short one phrase answers for the question\"\n",
    "enc_len = len(enc.encode(INSTRUCTION_STR))\n",
    "print(enc_len)\n",
    "enc_len = len(enc.encode(NO_CONTEXT_INSTRUCTION_STR))\n",
    "print(enc_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bm25_dataset_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/afreens/ragged/token_calculation.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbabel-1-23/home/afreens/ragged/token_calculation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m RETRIEVER_FOLDER \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mBASE_FOLDER\u001b[39m}\u001b[39;00m\u001b[39m/retriever_results\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbabel-1-23/home/afreens/ragged/token_calculation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m write_folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/data/tir/projects/tir6/general/afreens/dbqa/retriever_results/token_count\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbabel-1-23/home/afreens/ragged/token_calculation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m dataset, path \u001b[39min\u001b[39;00m bm25_dataset_map\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbabel-1-23/home/afreens/ragged/token_calculation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     retriever_data_path \u001b[39m=\u001b[39m path\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbabel-1-23/home/afreens/ragged/token_calculation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     retriever_eval_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(RETRIEVER_FOLDER, \u001b[39m\"\u001b[39m\u001b[39mevaluations\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mbm25\u001b[39m\u001b[39m\"\u001b[39m, dataset_map[dataset])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bm25_dataset_map' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ragged.reader.utils import merge_retriever_data_and_eval_results\n",
    "BASE_FOLDER = \"/data/tir/projects/tir6/general/afreens/dbqa\"\n",
    "RETRIEVER_FOLDER = f\"{BASE_FOLDER}/retriever_results\"\n",
    "\n",
    "\n",
    "write_folder = \"/data/tir/projects/tir6/general/afreens/dbqa/retriever_results/token_count\"\n",
    "for dataset, path in bm25_dataset_map.items():\n",
    "\n",
    "    retriever_data_path = path\n",
    "    retriever_eval_path = os.path.join(RETRIEVER_FOLDER, \"evaluations\",\"bm25\", dataset_map[dataset])\n",
    "    print(retriever_data_path)\n",
    "    print(retriever_eval_path)\n",
    "    retriever_data = merge_retriever_data_and_eval_results(retriever_data_path, retriever_eval_path)\n",
    "    # data = load_jsonl(path)\n",
    "    token_data = []\n",
    "    for d in retriever_data:\n",
    "        instance_id = d[\"id\"]\n",
    "        question = d[\"input\"]\n",
    "        outputs = d[\"output\"][0][\"provenance\"]\n",
    "        output_tokens = [len(enc.encode(o[\"text\"])) for o in outputs[:50]]\n",
    "        par_id_match = [o[\"wiki_par_id_match\"] for o in outputs[:50]]\n",
    "        token_data.append({\n",
    "            \"instance_id\": instance_id,\n",
    "            \"question_tokens\" : len(enc.encode(question)),\n",
    "            \"output_tokens\" : output_tokens,\n",
    "            \"par_id_match\": par_id_match\n",
    "        })\n",
    "    save_jsonl(token_data, f\"{write_folder}/{dataset}.jsonl\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/tir/projects/tir6/general/afreens/dbqa/retriever_results/token_count/colbert/nq.jsonl\n",
      "loading from /data/tir/projects/tir6/general/afreens/dbqa/retriever_results/token_count/colbert/nq.jsonl\n",
      "nq\n",
      "output_tokens 28370\n",
      "/data/tir/projects/tir6/general/afreens/dbqa/retriever_results/token_count/colbert/bioasq.jsonl\n",
      "loading from /data/tir/projects/tir6/general/afreens/dbqa/retriever_results/token_count/colbert/bioasq.jsonl\n",
      "bioasq\n",
      "output_tokens 38370\n",
      "/data/tir/projects/tir6/general/afreens/dbqa/retriever_results/token_count/colbert/hotpotqa.jsonl\n",
      "loading from /data/tir/projects/tir6/general/afreens/dbqa/retriever_results/token_count/colbert/hotpotqa.jsonl\n",
      "hotpotqa\n",
      "output_tokens 56000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for dataset in colbert_dataset_map:\n",
    "    top_k = {}\n",
    "    top_pos = {}\n",
    "    no_context = 0\n",
    "    path = f\"{write_folder}/colbert/{dataset}.jsonl\"\n",
    "    print(path)\n",
    "    data = load_jsonl(path, sort_by_id=False)\n",
    "    for k in [0,1,2,3, 5, 10, 20, 30, 50]:\n",
    "        # print(k)\n",
    "        # print([x[\"output_tokens\"][:k] for x in data])\n",
    "        top_k[k] = sum([sum(x[\"output_tokens\"][:k]) for x in data])\n",
    "        top_k[k] += sum([x[\"question_tokens\"] for x in data])\n",
    "        top_k[k] += len(data) * 9 if k==0 else len(data) * 13\n",
    "        if k>0:\n",
    "            total = 0\n",
    "            for x in data:\n",
    "                positive_data = []\n",
    "                for o, p in zip(x[\"output_tokens\"], x[\"par_id_match\"]):\n",
    "                    if p:\n",
    "                        positive_data.append(o)\n",
    "                total+= (sum(positive_data[:k]) + x[\"question_tokens\"])\n",
    "            top_pos[k] = total + len(data)*13\n",
    "\n",
    "    print(dataset)\n",
    "    print(\"top_k\", top_k)\n",
    "    print(\"top_pos\", top_pos)\n",
    "\n",
    "    print(\"output_tokens\", len(data)*10)\n",
    "            \n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kilt37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
